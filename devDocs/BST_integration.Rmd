---
title: "Integration of the core data of BST, using Roy's scripts"
author: "Marius Bottin"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: 
   pdf_document:
     toc: true
     toc_depth: 5
     number_sections: true
     latex_engine: xelatex
always_allow_html: true
fontsize: 11pt
geometry: "left=3cm,right=3cm,top=3cm,bottom=3cm"
linkcolor: gray
urlcolor: blue
citecolor: cyan
header-includes:
  - \usepackage{colortbl}
  - \usepackage{xcolor}       
  - \usepackage{lscape}
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
--- 


***************

```{r, setup, message=F, warning=F, include=F}
require(knitr)&require(RPostgreSQL)&require(formatR)&require(kableExtra)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
opts_chunk$set(cache=F,fig.path="../../Fig/BST_integration",tidy='styler',cache.rebuild = F,formatSQL = TRUE, size='scriptsize',
               echo=T, message=T, warning=T)
options(knitr.kable.NA = '---')
source("../functions/extract_function.R")
source("../functions/source_rmd.R")
```


The idea here is to try and integrate the BST (Bosque Seco Tropical) data in the database, using Roy's scripts, without transforming them in re-usable functions just yet, in order to have a functional database, and to determine what will be the potential problems to address.


# Reading the data with Roy's scripts

```{r, warning=F}
folderData <- "../../CodeRoy/BasesHumboldt-MV/core/"
folderMetadata <- paste0(folderData,"metadata/")
folderCensus0 <- paste0(folderData,"census0/")
folderCensus1 <- paste0(folderData,"census1/")
folderDates <- paste0(folderData,"dates/")
folderMembers <- paste0(folderData,"members/")
folderTaxonomy <- paste0(folderData,"taxonomy/")
source("../scripts/codesR/1.imput.metadata.R")
source("../scripts/codesR/2.imput.taxonomy.R")
source("../scripts/codesR/3.imput.censuses.census0.R")
source("../scripts/codesR/4.imput.dates.R")
source("../scripts/codesR/5.imput.members.R")
source("../scripts/codesR/6.input.census1.R")
```

Roy's scripts consist in storing all the data in a *"dataForests"* variable.
```{r}
names(dataForests)
```



# Adapting the data to the database

## Separating event and inputs

The first thing to do is to check, by plots, which files/data we have

```{r}
plotNames <- unique(c(
names(dataForests$metadata),
names(dataForests$taxonomy),
names(dataForests$censuses$census0),
names(dataForests$censuses$census1$growth1),
names(dataForests$censuses$census1$mortality1),
names(dataForests$censuses$census1$recruitment1),
names(dataForests$dates),
names(dataForests$members)
))
tabElementsPlot <- cbind(
metadata = plotNames %in% names(dataForests$metadata),
taxonomy = plotNames %in% names(dataForests$taxonomy),
census0 = plotNames %in% names(dataForests$censuses$census0),
census1 = plotNames %in% names(dataForests$censuses$census1$growth1),
mortality1 = plotNames %in% names(dataForests$censuses$census1$mortality1),
recruitment1 = plotNames %in% names(dataForests$censuses$census1$recruitment1),
dates = plotNames %in% names(dataForests$dates),
members = plotNames %in% names(dataForests$members)
)
rownames(tabElementsPlot) <- plotNames

kable(tabElementsPlot, booktab = T, longtable = T, label = NA, caption = "\\label{elePlot}Elements given by plots") %>%
  kable_styling(latex_options = c("repeat_header")) %>%
  column_spec(2,background = ifelse(tabElementsPlot[,1],"CornflowerBlue","OrangeRed")) %>%
  column_spec(3,background = ifelse(tabElementsPlot[,2],"CornflowerBlue","OrangeRed")) %>%
  column_spec(4,background = ifelse(tabElementsPlot[,3],"CornflowerBlue","OrangeRed")) %>%
  column_spec(5,background = ifelse(tabElementsPlot[,4],"CornflowerBlue","OrangeRed")) %>%
  column_spec(6,background = ifelse(tabElementsPlot[,5],"CornflowerBlue","OrangeRed")) %>%
  column_spec(7,background = ifelse(tabElementsPlot[,6],"CornflowerBlue","OrangeRed")) %>%
  column_spec(8,background = ifelse(tabElementsPlot[,7],"CornflowerBlue","OrangeRed")) %>%
  column_spec(9,background = ifelse(tabElementsPlot[,8],"CornflowerBlue","OrangeRed"))
```

### dates from the dates and other tables

In table \ref{elePlot}, we can see that some of the plots do not have any information concerning the dates, which might become problematic when we will assign them a cd_input...

The thing is, if they have a taxonomy tables, there might be record dates that might serve as field dates...
So, we need to check what is the relationship between dates given for taxonomy and date tables.


```{r, warning=FALSE}
raw_csv <- lapply(dir(folderData,recursive = T,pattern="\\.csv$"),function(x,d)
{read.csv(paste0(d,x))},d=folderData)
names(raw_csv) <- dir(folderData, recursive = T, pattern = "\\.csv$")
rawCsvRead<-
datesTaxonomy <- lapply(dataForests$taxonomy,function(x)unique(na.omit(x$eventDate)))
gpsDateTaxonomy <- sapply(datesTaxonomy,function(x)
  {
  if ( length(x) == 0 ) return(data.frame(start = NULL, end = NULL))
  if ( length(x) == 1 ) return(data.frame(start = x, end = x))
  gps <- cutree(hclust(dist(x)),h = 15)
  return(Reduce(rbind,tapply(x,gps,function(y)data.frame(start=min(y), end=max(y)),simplify = F)))
  }
  )

A<-lapply(plotNames,function(x,y,z)
{
  list(date1=y[[x]],date2=z[[x]])
},y=dataForests$dates,z=gpsDateTaxonomy)
```

Here is an example where the dates as read by Roy's function may be false:

```{r}
gpsDateTaxonomy$RosarioIntermedio
dataForests$dates$RosarioIntermedio
raw_csv$`dates/dates_RosarioIntermedio.csv`
unique(raw_csv$`taxonomy/taxonomy_RosarioIntermedio.csv`$eventDate)
```

Instead of march, the dates should be the 3rd of december.
Therefore, to avoid this kind of problems, we need to read all of the dates given for a plot at once, in order to choose the format which allows to make a group of dates where the distances are minimal.

******************

**The dates may have problems, but resolving those may be very complicated and would not guarantee for sure that no error is still there.
Therefore, we'll keep them here and make some clear messages in the import functions, so people can correct them by hand**

*****************

### separation by input

```{r}
#require(vistime)
(namesDates <- names(dataForests$dates))
tabEvents<-data.frame(plot=rep(namesDates,sapply(dataForests$dates,nrow)),Reduce(rbind,dataForests$dates))
#forGraph<-data.frame(event=tabEvents$measuringType,start = tabEvents$eventDate)
#vistime(forGraph)
sort(tabEvents$eventDate)
tabEvents <- tabEvents[order(tabEvents$eventDate),]
inputs<-vector(mode="list",length=nrow(tabEvents))
for(i in 1:length(inputs))
{
  inputs[[i]]$dates<-tabEvents[i,]
}
names(dataForests)
A <- lapply(inputs,function(x,l2)
{
  res <- list()
  plotName <- x$dates$plot
  typeCensus <- x$dates$measuringType
  #metadata
  res$metadata <- l2$metadata[[plotName]]
  #census
  if(typeCensus=="census0")
  {
    res$census <- l2$censuses$census0[[plotName]]
  }else
  {
    
  }
  return(res)
},l2 = dataForests)
```

# With formats
```{r}
source("../functions/extract_function.R")
```



## Reading raw files

```{r code=extractFunction("../functions/specs.R","test_regex_multi")}
eval(parse(text = extractFunction("../functions/specs.R","test_regex_multi")))
```

```{r code=extractFunction("../functions/input.R","read_rawFile")}
eval(parse(text = extractFunction("../functions/input.R","read_rawFile")))
```

```{r code=extractFunction("../functions/input.R","read_rawFiles")}
eval(parse(text = extractFunction("../functions/input.R","read_rawFiles")))
```

```{r}
rawFiles <- read_rawFiles("../../CodeRoy/BasesHumboldt-MV/core/",typeFiles="csv")
```

# Preformatting

In the case of the BST_csv format, it only consists in transposing the metadata table
```{r, code=extractFunction("../functions/input.R","preformat_tables")}
eval(parse(text = extractFunction("../functions/input.R","preformat_tables")))
```

```{r}
eval(parse(text = extractFunction("../functions/specs.R","maxVersion")))
```


```{r}
eval(parse(text = extractFunction("../functions/specs.R","getInputSpec")))
```


```{r}
sib_user <- dbConnect(PostgreSQL(),dbname = "sib_plot", user = "sib_user")
rawFiles <- preformat_tables(rawFiles, sib_user, "BST_csv")
```


# Separation and recognition of tables

```{r, code=extractFunction("../functions/input.R","recog_tables")}
eval(parse(text = extractFunction("../functions/input.R","recog_tables")))
```

```{r}
sib_user <- dbConnect(PostgreSQL(), user = "sib_user", dbname = "sib_plot")
BST_csv_spec <- getInputSpec(sib_user,"BST_csv")
recoTables <- recog_tables(rawFiles = rawFiles ,conn = sib_user,formatName = "BST_csv")
```


# Separation of inputs
```{r}
eval(parse(text=extractFunction("../functions/input.R","input_sep")))
sepInputs <- input_sep(rawFiles, recoTables, sib_user, "BST_csv","0.3")
```

# Checking input self-integrity



```{r}
checkSelfInteg <- lapply(sepInputs,checkInputSelfIntegrity, conn = sib_user,formatName = "BST_csv", formatVersion="0.3")
tabOK <- sapply(checkSelfInteg,function(x)sapply(x$selfInteg,function(y)y$ok))
rowSums(!tabOK)
```

```{r}
pbFieldMandat <- Reduce(rbind,lapply(checkSelfInteg,function(x)x$selfInteg$mandatFieldNa$pb))
table(interaction(pbFieldMandat[c("tablename","fieldname")], drop = T))
```

```{r}
Reduce(rbind,lapply(checkSelfInteg,function(x)
{
  if (!x$selfInteg$mandatFieldNa$ok && any(x$selfInteg$mandatFieldNa$pb$fieldname == "tag"))
  {
    return(x$input$event)
  }else{
    return(data.frame())
  }
}))
```
```{r}
pbTypeof <- Reduce(rbind,lapply(checkSelfInteg,function(x)
  data.frame(plot = rep(x$input$event[1], nrow(x$selfInteg$typeofRowError$pb)), 
             event = rep(x$input$event[2], nrow(x$selfInteg$typeofRowError$pb)), 
             x$selfInteg$typeofRowError$pb)))
```

```{r}
pbMaxChar <- Reduce(rbind,lapply(checkSelfInteg,function(x)
  data.frame(plot = rep(x$input$event["plot"], nrow(x$selfInteg$maxChar$pb)), 
             event = rep(x$input$event["event"], nrow(x$selfInteg$maxChar$pb)),
             x$selfInteg$maxChar$pb)))
table(interaction(pbMaxChar[c("tablename","fieldname")], drop=T))
```

```{r}
pbUniques <- Reduce(rbind,lapply(checkSelfInteg,function(x)
  data.frame(plot = rep(x$input$event["plot"], nrow(x$selfInteg$Uniques$pb)), 
             event = rep(x$input$event["event"], nrow(x$selfInteg$Uniques$pb)),
             x$selfInteg$Uniques$pb)))
table(interaction(pbUniques[c("tablename","fieldname")], drop = T))
```

