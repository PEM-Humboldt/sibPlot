---
title: "Analysing file input for the RDS format"
author: "Marius Bottin"
date: '`r format(Sys.time(), "%d %B, %Y")`'
bibliography: "/home/marius/Travail/Bibliotheque/jabref/UNAL.bib"
csl: "/home/marius/Travail/Bibliotheque/CSL/chicago.csl"
output: 
   pdf_document:
     toc: true
     toc_depth: 5
     number_sections: true
fontsize: 11pt
geometry: "left=3cm,right=3cm,top=3cm,bottom=3cm"
linkcolor: gray
urlcolor: blue
citecolor: cyan
header-includes:
  - \usepackage{colortbl}
  - \usepackage{xcolor}       
  - \usepackage{lscape}
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
--- 

```{r, setup}
require(knitr) & require(RPostgreSQL) & require(formatR) & require(kableExtra) & require(openxlsx)
opts_chunk$set(cache=F,fig.path="./Fig/",tidy='styler',cache.rebuild = F,formatSQL = TRUE)
#fileFunctions<-dir("../sib_plot/functions/",pattern=".*\\.R")
#sapply(fileFunctions,function(x)source(paste("../sib_plot/functions/",x,sep="")))
source("../functions/extract_function.R")
```

# Create format specification for later checks

## Reading specification files from Roy


```{r, code=extractFunction("../functions/readingFile.R",nameFunction = "xl_sep_table")}
eval(parse(text=extractFunction("../functions/readingFile.R",nameFunction = "xl_sep_table")))
```

Here we extract the specifications from Roy and we made it in a table which we will be able to modify in excel and use directly as an input data for checking compatibility of input files.

```{r, tidy=TRUE,tidy.opts=list(width.cutoff=70)}
roySpec<-xl_sep_table("../../AnalysisDocumentosRoy/RelacionalDAta.xlsx" , sheet="Sheet1")
names(roySpec)<-sapply(roySpec , function(x) sub("_plotName$","" , colnames(x)[1]))
for(i in 1:length(roySpec)) { colnames(roySpec[[i]])[1] <- "field"}
tabRoySpec <- data.frame(table = rep(names(roySpec) , sapply(roySpec , nrow)) , Reduce(rbind , roySpec))
table(tabRoySpec$optimalCharacters)
tabRoySpec$typeof<-NA
tabRoySpec$typeof[tabRoySpec$optimalCharacters=="integer"]<-"integer"
tabRoySpec$typeof[tabRoySpec$optimalCharacters=="numeric"]<-"double"
tabRoySpec$typeof[grep("character",tabRoySpec$optimalCharacters)]<-"character"
tabRoySpec$typeof[tabRoySpec$field=="tag"]<-"character"
tabRoySpec$maxChar<-NA
regexMax<-".*[-–](max)?([0-9]{1,2}).*"
tabRoySpec$maxChar[grep(regexMax , tabRoySpec$optimalCharacters)]<-as.integer(sub(regexMax , "\\2" , tabRoySpec$optimalCharacters[grep(regexMax , tabRoySpec$optimalCharacters)]))
tabRoySpec$regex <- tabRoySpec$maxNum <- tabRoySpec$minNum <- NA
tabRoySpec[ , c("table" , "field" , "example" , "typeof" , "maxChar" , "regex" , "maxNum" , "minNum")]  %>%
  head(20) %>% kable(booktab=T,caption="Specification of the fields (20 first lines)") %>% kable_styling(font_size=8)
tabRoySpec_Table<-data.frame(typeTable=unique(tabRoySpec$table),regex=paste0("^",unique(tabRoySpec$table),"$"))
```

Then we create the Excel file (with only the specifications extracted from Roy's file).
To specify details in the files, we may copy this file and modify it.
Then the modified file will be read to apply in test functions.

```{r}
dosSpec<-"../inputSpec/"
if(!file.exists(dosSpec))
{dir.create(dosSpec)}
#wb<-createWorkbook()
#addWorksheet(wb,sheetName="tableSpec")
#addWorksheet(wb,sheetName="fieldSpec")
#writeDataTable(wb,sheet=1,x=tabRoySpec_Table,colNames = T , rowNames = F )
#writeDataTable(wb,sheet=2,x=tabRoySpec,colNames = T , rowNames = F )
#setColWidths(wb,1,cols=1:ncol(tabRoySpec_Table),"auto")
#setColWidths(wb,2,cols=1:ncol(tabRoySpec),"auto")
#saveWorkbook(wb,paste0(dosSpec,"/","spec_csvPermanentBST_Roy.xlsx"),overwrite=T)
#if(!"spec_csvPermanentBST_Final.xlsx"%in%dir(dosSpec))
#{saveWorkbook(wb,paste0(dosSpec,"/","spec_csvPermanentBST_Final.xlsx"))}

```

```
gsub("[“”]","\"",openxlsx::read.xlsx(paste0(dosSpec,"/","spec_csvPermanentBST_Final.xlsx"))[,2])
```


## Reading final specification
After having modified the final specification in the Excel file, we can read the specification in a function which will create the input format tests.

```{r, code=extractFunction("../functions/specs.R", "read_Xlspec")}
eval(parse(text=extractFunction("../functions/specs.R", "read_Xlspec")))
```

```{r, code=extractFunction("../functions/specs.R", "read_CsvSpec")}
eval(parse(text=extractFunction("../functions/specs.R", "read_CsvSpec")))
```

```{r}
#specs<-read_Xlspec(paste0(dosSpec,"/","spec_csvPermanentBST_Final.xlsx"))
specs<- read_CsvSpec(fileSpecTab = paste0(dosSpec,"/","spec_csvPermanentBST_tables.csv"),
                     fileSpecField = paste0(dosSpec,"/","spec_csvPermanentBST_fields.csv")
                     )
```


# Testing regex

```{r, code=extractFunction("../functions/specs.R", "test_regex_multi")}
eval(parse(text=extractFunction("../functions/specs.R", "test_regex_multi")))
```

```{r, code=extractFunction("../functions/specs.R", "test_regex")}
eval(parse(text=extractFunction("../functions/specs.R", "test_regex")))
```


# Checking data input structure in files

```{r}
# Here I will take some examples to work on input data from Roy's code

# I believe it would be a good thing to have first a function which checks files, files types etc
#dos<-"~/Travail/traitementDonnees/2021_Humboldt_Sib/CodeRoy/BasesHumboldt-MV/core/metadata/"
dos<-"../../CodeRoy/BasesHumboldt-MV/core"
```

```{r code=extractFunction("../functions/specs.R", "analyseCsvFile")}
eval(parse(text=extractFunction("../functions/specs.R", "analyseCsvFile")))
```


```{r}
an_fi<-analyseCsvFiles(dos,regex_types=specs$regex_tb)
```

```{r code=extractFunction("../functions/specs.R", "readCsvFiles")}
eval(parse(text=extractFunction("../functions/specs.R", "readCsvFiles")))
```


```{r}
firstRead<-readCsvFiles(an_fi$file,an_fi$type_cat)

# Function to check whether the names of the fields are the same than the ones prepared in the formats
listField<-tapply(specs$fi_spec$field,specs$fi_spec$table,function(x)x)
colRead<-lapply(firstRead,colnames)
checkNamesFields<-function(read,categ,listFieldCateg)
{
  
  corresColRef<-listFieldCateg[match(categ,names(listFieldCateg))]
  res<-mapply(function(nam,ref)
    {
      #allTrueSimple <- all(nam==ref)
      list(notDefined=setdiff(nam,ref),Missing=setdiff(ref,nam))
    },colListRead,corresColRef,SIMPLIFY = F)
  return(res)
}

#C<-checkNamesFields(read = colRead, categ = an_fi$type_cat, listFieldCateg = listField)
```


```{r}
names(table(an_fi$plot))[table(an_fi$plot)<5]
table(an_fi$type_cat)
#Which plot do not have any census0 (which seems to be basic for me)
plot_census0<-by(an_fi,an_fi$plot,function(x)any(x$type=="census0"),simplify = T)
names(which(!plot_census0))



#Function for treating dates (todo: check whether Roy's treatment is the same everywhere)
treatDates<- function(textDate)
{
  regexDate<-"^([0-9]{1,4})/([0-9]{1,4})/([0-9]{1,4})$"
  date3numbers<-grepl(textDate,regexDate)
  if(all(date3numbers))
  {
    part1<-sub(regexDate,"\\1",texDate)
    part2<-sub(regexDate,"\\2",texDate)
    part3<-sub(regexDate,"\\3",texDate)
    part1num<-as.integer(part1)
    part2num<-as.integer(part2)
    part3num<-as.integer(part3)
    # Which are years for sure
    p1y<-any(part1num>31)
    p2y<-any(part2num>31)
    p3y<-any(part3num>31)
    if((p1y+p2y+p3y)>1){
      stop("In the dates, more than one part can only be year")
      }else{
      
    }
  }else{
    stop("Some dates are not 3 numbers separated by \"/\"")
  }
  
}


# Function to check whether the names of the fields are the same than the ones prepared in the formats
checkNamesFields<-function(x)
  NA

# Function to check whether the types entered in the fields are the same that were prepared in the formats
checkTypesFields<-function(x)
  NA
  
  

dos<-"~/Travail/traitementDonnees/2021_Humboldt_Sib/CodeRoy/BasesHumboldt-MV/core/metadata/"
dir(dos)

ex<-("AltoSanJorgeInicial")
read.csv(paste0(dos,"/metadata_",ex,".csv"))



read_metadata<-function(file)
{
  NA
}
```
