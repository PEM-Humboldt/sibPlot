---
title: "Analyzing and reading the phytosociological files"
author: "Marius Bottin"
date: '`r format(Sys.time(), "%d %B, %Y")`'
bibliography: "/home/marius/Travail/Bibliotheque/jabref/UNAL.bib"
csl: "/home/marius/Travail/Bibliotheque/CSL/chicago.csl"
output: 
   pdf_document:
     toc: true
     toc_depth: 5
     number_sections: true
fontsize: 11pt
geometry: "left=3cm,right=3cm,top=3cm,bottom=3cm"
linkcolor: gray
urlcolor: blue
citecolor: cyan
header-includes:
  - \usepackage{colortbl}
  - \usepackage{xcolor}       
  - \usepackage{lscape}
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
--- 

```{r, setup}
require(knitr)&require(RPostgreSQL)&require(formatR)&require(kableExtra)
opts_chunk$set(cache=F,fig.path="../../Fig/phytosoc_read",tidy='styler',cache.rebuild = F,formatSQL = TRUE)
#fileFunctions<-dir("../sib_plot/functions/",pattern=".*\\.R")
#sapply(fileFunctions,function(x)source(paste("../sib_plot/functions/",x,sep="")))
```


# Merged cells

## The openxlsx methods for merged cells

The problem with phytosociological files is that they contain a lot of merged cells.

I first check on the functions of the package *openxlsx* if there was a solution to unmerge cells and replicate the values for all merged cells, but the option *fillMergedCells* of the function read.xlsx does not work.

Further search in the internal functions allowed me to find the following:

```{r}
require(openxlsx)
methods(read.xlsx)
A<-as.character(getAnywhere(read.xlsx.default))
cat(A,file="read.xlsx.default.R")
A<-readLines("read.xlsx.default.R")
A[grep("merge",A)]
file.remove("read.xlsx.default.R")
```


It seems complicated to look further in the methods, but it seems that the methods used in the *openxlsx* functions make a mapping of the merged cells.
The mapping is made after unzipping the formats of the xlsx files to read the xml information of the file.
```r
xlsxFile<-"../../XlTest/xl_files/Arreglo PERIJA HUMBOLDT (1).xlsx"
sheet<-"Hoja1"
na.strings<-"NA"
xmlDir <- file.path(tempdir(), paste0(sample(LETTERS, 10), collapse = ""), "_excelXMLRead")
xmlFiles <- unzip(xlsxFile, exdir = xmlDir)
worksheet <- xmlFiles[grepl(tolower(sheet), tolower(xmlFiles), fixed = TRUE)]
cell_info <- openxlsx:::getCellInfo(xmlFile = worksheet, sharedStrings = sharedStrings, skipEmptyRows = skipEmptyRows, startRow = startRow, rows = rows, getDates = detectDates)#29
merge_mapping <- mergeCell2mapping(cell_info$cellMerge)#31
```

### Work on openxlsx functions

Finally I made all the work with the *openxlsx* package.
I extracted the methods from the *openxlsx* package in a very dirty way (I had to use many times the "openxlsx:::" operande to extract inside hidden function from the package), which might become a problem when/if we will build a package.

All the work is in the file [mergedCells_fromopenxlsx.R](./mergedCells_fromopenxlsx.R).

All the code there are functions, so the idea is to source this R script and everything should work!

```{r}
source("./mergedCells_fromopenxlsx.R")
```

The important function in the code is: *xl_fillMerged*
It takes the following arguments:

```{r}
args(xl_fillMerged)
```

* fileXl is the name of the file with its (relative) path
* getWorkbook is a boolean which allows to get a *openxlsx* workbook when T. Otherwise the function return the data from all the sheets, after having separated and filled the merged cells with the merged value
* writeFile: boolean: do we want to write the modified file
* dos_unMerged is the path of the directory where we want to write the file, if not given the directory is the directory of the original file (note that the file will be called the same than the original file, but with "_unmerged" before the extension)
* overwrite: boolean, do we want to overwrite any file called like the unMerged file (note that the file will be called the same than the original file, but with "_unmerged" before the extension)


```{r}
xlsxFile<-"../../XlTest/xl_files/Tablas Perija Vegetacion Libro XVIII 05 octubre (1).xlsx"
sheet<-"Tabla 33"
mergedCells<-getCellMerge(xlsxFile = xlsxFile, sheet = sheet )
treatCellRange(mergedCells)
dos_unMerged<-"../../XlTest/xl_files/unmerged/"
xl_fillMerged(xlsxFile,dos_unMerged = dos_unMerged )
```

************************************

Note: I realized afterward that there might be a way to analyze directly the workbook object without having to pass through all this long process and working from there... 
Don't know why I did not think about that before
Hints: apply a "str" to a workbook of an excel file in *openxlsx*: there are some substructure concerning merged cells...


*************************************





## Python openpyxl method

*********************

**Note**:
At first I thought that it would be easier to work on some python code that I found on internet, but finally... not so easy!

Anyway I'll keep the code here because it might result easier when we will build a package if the hidden method functions of *openxlsx* are difficult to import in the package...

*********************


In internet, there are more information about the *openpyxl* python method

In order to use python3 in this document, we first call the package *reticulate* and then we choose the right python location:

We first need to install the openpyxl package
```{r}
require(reticulate)
#use_condaenv("r-reticulate")
#reticulate::conda_install(packages="openpyxl")
#reticulate::conda_install(packages="panda")
use_python("/usr/bin/python3")
```

Then the following code in Python3 allows to map the merged cells in a xlsx sheet (note that you need first to install the python *openpyxl* library:

```{python}
from openpyxl import load_workbook
wb=load_workbook("../../XlTest/xl_files/Tablas Perija Vegetacion Libro XVIII 05 octubre (1).xlsx")
sheet_ranges=wb['Tabla 33']
print(sheet_ranges.merged_cells.ranges)
```

The idea then is to export the merged cells in a file so we can read it from R and allow to merge them in R.
It is a temporary solution and a "all R" solution would be much more appropriate in the future, but that is what we got for now.


So now, let's try to pass address of the files and sheets we need to treat from R to python

```{r}
require(openxlsx)
dos<-"../../XlTest/xl_files/"
files<-dir(dos,pattern=".*.xlsx$")
sheetNames<-lapply(paste(dos,files,sep="/"),getSheetNames)
names(sheetNames)<-paste(dos,files,sep="")
py$files_xl=rep(names(sheetNames),sapply(sheetNames, length))
py$xl_sheet=unlist(sheetNames)
```

```python
files_xl
xl_sheet
print(len(files_xl))
print(len(xl_sheet))
txtFile = open("mergedFiles.txt","a+")
for i in range(len(files_xl)):
  wb=load_workbook(files_xl[i])
  sheet_ranges=wb[xl_sheet[i]]
  txtFile.write(files_xl[i])
  txtFile.write("\t")
  txtFile.write(xl_sheet[i])
  txtFile.write("\t")
  merged = sheet_ranges.merged_cells.ranges
  for j in range(len(merged))
    txtFile.write(merged[j])



```


# Exploration of first phytosociological files

## Reading the files

```{r}
dos<-"../../docFito/"
files<-dir(dos,recursive = T,pattern="\\.xlsx$")
files<-files[!grepl("_unmerged",files)]
dos_files<-paste(dos,files,sep="/")
```

First we will create the unmerged-cells xlsx files in the unmerged folder:

```{r}
data_unMerged<-lapply(dos_files,xl_fillMerged,getWorkbook=F,dos_unMerged=paste0(dos,"unmergedCellsXlsx/"))
```

Then we read the excel files in a raw form in order to analyse their format:

```{r}
data_raw<-lapply(dos_files,function(x)
  {A<-openxlsx::getSheetNames(x)
  lapply(A,read.xlsx,xlsxFile=x,colNames=F,skipEmptyRows=F,skipEmptyCols=F)
  })
names(data_raw)<-names(data_unMerged)<-dos_files
data_raw<-mapply(function(x,y){names(x)<-names(y);return(x)},data_raw,data_unMerged)
```

## Determining what data contain each sheet

En los archivos enviados por O. Rangel, hay diferentes tipos de datos:

1. tabla de clasificación fitosociologica (ver "Arreglo PERIJA HUMBOLDT (1).xlsx"). Este tipo de tabla parece consistir en una sola tabla clara, cuadrada, y los nombres de columnas en la linea 1 debería permitir ver si un sheet es corresponde a este tipo
2. tabla de ubicación (ver "Tablas Perija Vegetacion Libro XVIII 05 octubre (1).xlsx", sheet 1). Parece que este tipo de tabla siempre tiene su descripción en la primera celda. 
3. tabla de ubicación y area (ver "Tablas Perija Vegetacion Libro XVIII 05 octubre (1).xlsx", sheet 2)
4. tabla de levantamiento (ver "Tablas Perija Vegetacion Libro XVIII 05 octubre (1).xlsx", sheet 3 a n y los sheet de "vegetacion paramo perija (1).xlsx"). Esas tablas están en 2 partes: una parte de descripción de levantamiento, y una parte dando la composición de los levantamientos. Podríamos basarnos en varios criterios para determinar si estamos en este tipo de datos, pero uno de los más practico podría ser basarse en la mención de Área basal, Cobertura o cobertura relativa: este corresponde a una celda "merged", que toma toda una linea (a veces sin la primera celda de la linea)






```{r}
lapply(data_unMerged,sapply,function(x)x[1,1])
```

This function will check whether the first cell of the sheet contains some description of the table
```{r}
firstCellTitle<-function(sheetRawData)
{
  regexDesc<-"^ *Tabla *[0-9]{1,3}\\."
  grepl(regexDesc,sheetRawData[1,1])
}
lapply(data_unMerged,sapply,firstCellTitle)
```


This one will check whether there is a line containing only the description of the coverage method and will return:

* a boolean telling whether it found it
* which one (see regexes in code for details)
* at which line

```{r}
linePhytoCoverage<-function(sheetRawData,headRows=15)
{
  emptyRow<-which(apply(sheetRawData,1,function(x)all(is.na(x))))
  #stopifnot(all(emptyRow>headRows))
  uniqueOnRow_head<-apply(sheetRawData[1:headRows,],1,function(x)
    unique(na.omit(x))
    )
  only1Value_head<-sapply(uniqueOnRow_head,length)==1
  regexes_phytoCoverage<-c(areaBasal="^ *[ÁA]rea *basal *(\\(\\%\\))? *$" , cobertura="^ *Cobertura *(\\(%\\))? *$" , coberturaRelativa="^ *Cobertura *relativa *(\\(%\\))? *$")
  #regexes_phytoCoverage<-c(areaBasal="^ *[ÁA]rea *basal *" , cobertura="$ *Cobertura *(\\(%\\))? *$" , coberturaRelativa="$ *Cobertura *relativa *(\\(%\\))? *$")
  testRegexes<-matrix(Reduce(c,lapply(regexes_phytoCoverage,grepl,uniqueOnRow_head[only1Value_head])),ncol=sum(only1Value_head),nrow=length(regexes_phytoCoverage))
  w_t<-which(testRegexes,arr.ind = T)
  stopifnot(nrow(w_t)<=1)
  if(nrow(w_t)==1)
  {
    res<-list(lineFound=T,
           type=names(regexes_phytoCoverage)[w_t[,"row"]],
           line=which(only1Value_head)[w_t[,"col"]]
           )
  }else{
    res<-list(lineFound=F,
           type=NA,
           line=NA
           )
  }
  return(res)
}
```

The function linePhytoCoverage works on unmerged and raw data extracted from the excel files and allows to find the line which:

* makes the separation between metadata and compositions
* explicit which measure of coverage is used in the composition table

Moreover, it allows to recognise the sheets which correspond to the "tabla de levantamiento" (it might not be sufficient for that goal on the long run, but it works with the few files we got for now).

```{r}
lapply(data_raw,sapply,linePhytoCoverage)
lapply(data_unMerged,sapply,linePhytoCoverage)
```

## Metadata extraction

```{r}

getMetadataPhytoXl<-function(sheet_unMerged)# In the future we might need to pass the file and sheet to the function (in order to keep them in the metadata)
{
  lpc_info<-linePhytoCoverage(sheet_unMerged)
  firstLineTitle<-firstCellTitle(sheet_unMerged)
  if(firstLineTitle){
    title<-sheet_unMerged[1,1]
  }else{
    title<-NULL
  }
  if(firstLineTitle)row_meta <- 2:lpc_info$line else row_meta<- 1:lpc_info$line # fix lpc_info$line is 1 too much
  col_meta<-1:ncol(sheet_unMerged)
  COLN<-sheet_unMerged[row_meta,1]
  dupCOLN<-duplicated(COLN)
  tempoMeta<-sheet_unMerged[row_meta,col_meta]
  if(length(dupCOLN)>0)
  {
    dupliValues<- unique(COLN[duplicated(COLN)])
    w_dupliValues<-lapply(dupliValues,function(x,coln)which(coln==x),coln=COLN)
    for(i in 1:length(w_dupliValues))
    {
      tempoMeta[w_dupliValues[[i]][1], 2:ncol(tempoMeta)]<-apply(tempoMeta[w_dupliValues[[i]], 2:ncol(tempoMeta)], 2,
                                                                 function(x){
                                                                   paste(x[!duplicated(x)],sep=" ",collapse=" ")
                                                                 })
      tempoMeta<-tempoMeta[-w_dupliValues[[i]][2:length(w_dupliValues[[i]])],]
    }
  }
  (tab_meta<-type.convert(data.frame(t(tempoMeta[,-1])),as.is=T))
  colnames(tab_meta)<-c(tempoMeta[1:(nrow(tempoMeta)-1),1],"typeCoverage")
  return(tab_meta)
}
```

## Metadata check

## Metadata check/compare


## Composition data extraction

### Extracting squared regions in a composition data table in excel

Putting a square around a part of a composition table in a phytosociological data table as actually a very specific meaning.
It means that the relevés in the square are considered part of a common syntaxa, and that the species in the square are diagnostic species for determining this syntaxa.

Here is a function that can extract such squares in an excel sheet:

```{r}
wb<-loadWorkbook(xlsxFile)
getSquaredBorderRegions<-function(wb,sheet)
{
  style_sheet<-wb$styleObjects[sapply(wb$styleObjects,function(x)x$sheet)==sheet]
  borderStyle<-sapply(style_sheet,function(x)
  {
    border<-c(
      bottom=!is.null(x[[1]]$borderBottom),
      top=!is.null(x[[1]]$borderTop),
      left=!is.null(x[[1]]$borderLeft),
      right=!is.null(x[[1]]$borderRight)
    )
    if(!sum(border)%in%c(1,2))
    {return(NA)}
    if(sum(border)==1)
    {return(names(border)[border])}
    if(sum(border)==2)
    {
      if(all(border[c(2,3)])){return("topleft")}
      if(all(border[c(2,4)])){return("topright")}
      if(all(border[c(1,3)])){return("bottomleft")}
      if(all(border[c(1,4)])){return("bottomright")}
    }
    return(NA)
  })
  cellBorder<-Reduce(rbind.data.frame,mapply(function(x,y)
  {
    if(is.na(y)){return(NULL)}
    return(data.frame(r=x$rows,c=x$cols,border=y))
  },style_sheet,borderStyle,SIMPLIFY=F))
  res<-data.frame(topleft.x=NULL,topleft.y=NULL,bottomright.x=NULL,bottomright.y=NULL)
  if(nrow(cellBorder)==0){return(res)}
  cellBorder<-cellBorder[order(cellBorder$r,cellBorder$c),]
  topLefts<-cellBorder[cellBorder$border=="topleft",]
  for(i in 1:nrow(topLefts))
  {
    curTopLeft<-as.list(topLefts[i,])
    #checkTopRight and top
    corresTopRights<-cellBorder[cellBorder$border=="topright"&
                                 cellBorder$r==curTopLeft$r&
                                 cellBorder$c>curTopLeft$c,]
    if(nrow(corresTopRights)==0){next}
    corresTopRight<-as.list(corresTopRights[which.min(corresTopRights$c),])
    condTopOK<-(
      (curTopLeft$c+1)==corresTopRight$c|
      all(
      (curTopLeft$c+1):(corresTopRight$c-1)%in%cellBorder[cellBorder$border=="top"&cellBorder$r==curTopLeft$r,"c"]))
    if(!condTopOK){next}
    #check bottomleft and left
    corresBottomLefts<-cellBorder[cellBorder$border=="bottomleft"&
                                 cellBorder$c==curTopLeft$c&
                                 cellBorder$r>curTopLeft$r,]
    if(nrow(corresBottomLefts)==0){next}
    corresBottomLeft<-as.list(corresBottomLefts[which.min(corresBottomLefts$c),])
    condLeftOK<-(
      (curTopLeft$r+1)==corresBottomLeft$r|
        all(
      (curTopLeft$r+1):(corresBottomLeft$r-1)%in%cellBorder[cellBorder$border=="left"&cellBorder$c==curTopLeft$c,"r"])
    )
    if(!condLeftOK){next}
      # checking bottomright
    condBottomRightOK<-any(cellBorder$border=="bottomright"&cellBorder$r==corresBottomLeft$r&cellBorder$c==corresTopRight$c)
    if(!condBottomRightOK){next}
      #checking bottom
    condBottomOK<-(curTopLeft$c+1)==corresTopRight$c|all(
        (curTopLeft$c+1):(corresTopRight$c-1)%in%cellBorder[cellBorder$border=="bottom"&cellBorder$r==corresBottomLeft$r,"c"]
      )
    if(!condBottomOK){next}
      #checking right
    condRightOK<-(curTopLeft$r+1)==corresBottomLeft$r|all(
         (curTopLeft$r+1):(corresBottomLeft$r-1)%in%cellBorder[cellBorder$border=="right"&cellBorder$c==corresTopRight$c,"r"]
      )
    if(!condRightOK){next}
    #append res
    res<-rbind(res,data.frame(topleft.x=curTopLeft$c,topleft.y=curTopLeft$r,bottomright.x=corresTopRight$c,bottomright.y=corresBottomLeft$r))
    
  }
  return(res)
}

getSquaredBorderRegions(wb,sheet)
```



The following functions will treat the names as given in a Excel file of phytosociology from O. Rangel.

The idea is that we apply various operation to separate the different parts of the names which may include important information.
This is done by recognizing structures in the names, extracting information from some parts of the taxonomic names and modifying recursively the name vector until it is a simple taxonomic name that can be taxonomically analyzed.
Then the taxonomic level is guessed, and the different parts of the names are extracted

The order of the operations may be of great importance, so here is the order we used for the funtion:

1. clean spaces in the names (remove spaces at the end and the beginning, replace special spaces by simple space and remove double spaces)
1. Extract, treat and remove parentheses. Those can have special meaning in the files from O. Rangel
   + there are some references which look like some catalog references
   + in the case of rare species, there might be some information on the relevés where they are found and their cover
1. Extract, treat and remove cases of unprecise determination:
   + *cf.* Note that all the string after aff. will be extracted and removed, including whether there are some taxonomic sublevels there
   + *aff.* same as "*cf.*"
   + *ined.* at the end of the taxonomic denomination
   + *sp.* + number (the number is extracted as text and as it is)
   + *sp.* at the end of the taxonomic denomination
   + *spp.* at the end of the taxonomic denomination
1. Recognizing the undetermined taxa (recognizing the strings "undetermined", "indeterminado", "indeterminada")
1. Guessing of the taxonomic ranks of the taxa (from the suffix used if the name is of one word)
1. Extract, treat and remove the subspecific ranks
1. Checking whether all taxa have a form of species (2 names, uppercase only on the genus name) or genera/higher ranks
1. Extracting the genus and specific epithete of the species


```{r}
# create regex object (external to the functions) for guessing taxonomic levels
taxo_treatNames_plant<-list(
  regex_lev= c(
    undeter= "[UIui]ndetermin[ae]d[ao]?",
    subsp= "^([A-Z][[:alpha:]-]+) ([[:alpha:]-]+) subsp(\\.| ){1,2}([[:alpha:]-]+)$",
    var= "^([A-Z][[:alpha:]-]+) ([[:alpha:]-]+) var(\\.| ){1,2}([[:alpha:]-]+)$",
    sp= "^([A-Z][[:alpha:]-]+) ([[:alpha:]-]+)$",
    fam= "^([A-Z][[:alpha:]-]+aceae)$",
    subfam= "^([A-Z][[:alpha:]-]+oideae)$",
    supfam= "^([A-Z][[:alpha:]-]+acea)$",
    subor= "^([A-Z][[:alpha:]-]+ineae)$",
    or= "^([A-Z][[:alpha:]-]+ales)$",
    supor= "^([A-Z][[:alpha:]-]+anae)$",
    subcl= "^([A-Z][[:alpha:]-]+idae)$",
    phyl= "^([A-Z][[:alpha:]-]+phyta)$",
    subphyl= "^([A-Z][[:alpha:]-]+phytina)$",
    cl= "^([A-Z][[:alpha:]-]+opsida)$",
    subcl= "^([A-Z][[:alpha:]-]+opsida)$",
    tribe= "^([A-Z][[:alpha:]-]+eae)$",
    gn= "^([A-Z][[:alpha:]-]+)$"
  ),
  exceptions= data.frame(lev=c("fam"),name=c("Leguminosae")),
  extracPart= list(
    subsp=c("genus"="\\1","sp_epi"="\\2","subspecies"="\\4"),
    var=c("genus"="\\1","sp_epi"="\\2","variety"="\\4"),
    sp=c("genus"="\\1","sp_epi"="\\2")
  )
  
)

guess_level<- function(taxNames,regex_lev,exceptions,order_reg=NA)
{
  if(is.na(order_reg))
  {
    order_reg=names(regex_lev)
  }
  regex_lev<-regex_lev[match(names(regex_lev),order_reg)]
  testRegex<-sapply(regex_lev,function(reg,nam)grepl(reg,nam),nam=taxNames)
  unable_guess<-which(rowSums(testRegex)==0)
  if(length(unable_guess)>0)
  {
    for(i in unable_guess)
    {
      warning(paste0("We were unable to guess the taxonomic level of \"",taxNames[unable_guess],"\""))
    }
  }
  guessed<- colnames(testRegex)[apply(testRegex,1,function(x)which(x)[1])]
  guessed[taxNames%in%exceptions$name]<- na.omit(exceptions[match(taxNames,exceptions$name),"lev"])
  return(guessed)
}

extract_taxParts<- function(taxNames, tax_lev, regex_lev, extractPart)
{
  list_tax_lev<- tapply(taxNames,tax_lev,function(x)x)[names(extractPart)]
  regex_app<-regex_lev[names(extractPart)]
  separate<-mapply(function(names,regex,parts)
  {
    sapply(parts,function(x,n,r)sub(r,x,n),n=names,r=regex)
  },list_tax_lev,regex_app,extractPart)
  res<- vector(mode= "list",length= length(separate))
  for(i in 1:length(separate))
  {
    res[[i]]<-data.frame(id_m= match(list_tax_lev[[i]],taxNames),separate[[i]])
  }
  return(res)
}
```


```{r}
treatTaxNameXlPhyto<- function(taxNames, lev_regex, exceptions_guessLev, extract_part)
{
  # Keeping initial taxNames
  taxNames_init<-taxNames
  # Eliminate irrelevant spaces:
  taxNames<-sub("^[[:space:]]*","",taxNames)
  taxNames<-sub("[[:space:]]*$","",taxNames)
  taxNames<-sub("[[:space:]]+"," ",taxNames)
  # Working on parenthesis
  ## there seems to be different things in parentheses: external references to the species identification, and in the case of rare species: their presences in some relevés 
  regexParenth_all<-"(\\(|\\))"
  regexParenth<- "^([[:alnum:] \\.-]+)[[:space:]]*\\((.+)\\)$"
  caseParenth<-grepl(regexParenth, taxNames)
  caseParenth_all<-grepl(regexParenth_all, taxNames)
  weirdParenthesis<- which(caseParenth_all&!caseParenth)
  if(length(weirdParenthesis)>0)
  {
    for(i in weirdParenthesis)
        warning(paste("Taxon name:",taxNames_init[i],". We recognize a parenthesis case without being able to treat it."))
  }
  parenthesis<-character(length(taxNames))
  parenthesis[caseParenth]<- sub(regexParenth,"\\2",taxNames[caseParenth])
  taxNames[caseParenth]<- sub(regexParenth,"\\1",taxNames[caseParenth])
  taxNames[caseParenth]<- sub("[[:space:]]*$","",taxNames[caseParenth])
  sinParenth<-taxNames
  # Case 1: references for taxon definition?
  regexParDef<- "^[A-Z]{2,6} [0-9]{2,8}$"
  defTax<- character(length(taxNames))
  defTax[grep(regexParDef, parenthesis)]<- parenthesis[grep(regexParDef, parenthesis)]
  # Case 2: references for rare presences
  regexRare<- "^([A-Z]{1,5}[0-9]{1,5}/[0-9,]+; )*([A-Z]{1,5}[0-9]{1,5}/[0-9,]+)$"
  caseRegexRare<-grepl(regexRare, parenthesis)
  if(sum(caseRegexRare)>0){
    splitRare<- strsplit(parenthesis[caseRegexRare], "; ")
    split2Rare<- strsplit(Reduce(c,splitRare),"/")
    rarePres<- data.frame(matchTax= rep(which(caseRegexRare), sapply(splitRare, length)),
                releve= sapply(split2Rare, function(x)x[1]),
                coverage= as.double(sub(",",".",sapply(split2Rare, function(x)x[2])))
               )
  }else{rarePres<-list2DF(list(matchTax= NULL, releve= NULL,coverage=NULL))}
  noCase<- which(caseParenth& !grepl(regexParDef, parenthesis)& !caseRegexRare)
  stopifnot(length(noCase)==0)
  # keep as "CF" all what is after cf.
  regex_cf_all<-" cf\\.?"
  regex_cf<-"^([A-Za-z][[:alpha:]-]+) cf\\.? ?(.*)$"
  caseCf<-grepl(regex_cf,taxNames)
  weirdCf<-which(grepl(regex_cf_all,taxNames)&!grepl(regex_cf,taxNames))
  if(length(weirdCf)>0)
  {
    for(i in weirdCf)
      warning(paste("Taxon name:", taxNames_init[i], ". We recognize a cf. case without being able to treat it."))
  }
  CF<- character(length(taxNames))
  CF[caseCf]<- sub(regex_cf, "\\2",taxNames[caseCf])
  taxNames[caseCf]<-sub(regex_cf, "\\1", taxNames[caseCf])
  # keep as AFF all what is after aff.
  regex_aff_all<-" aff\\."
  regex_aff<-"^([A-Za-z][[:alpha:]-]+) aff\\. (.*)$"
  caseAff<-grepl(regex_aff,taxNames)
  weirdAff<-which(grepl(regex_aff_all,taxNames)&!grepl(regex_aff,taxNames))
  if(length(weirdAff)>0)
  {
    for(i in weirdAff)
      warning(paste("Taxon name:", taxNames_init[i], ". We recognize a aff. case without being able to treat it."))
  }
  AFF<- character(length(taxNames))
  AFF[caseAff]<- sub(regex_aff, "\\2",taxNames[caseAff])
  taxNames[caseAff]<-sub(regex_aff, "\\1", taxNames[caseAff])
  # ined. final
  regex_ined_fin<- "(.*) ined\\.$"
  INED<- grepl(regex_ined_fin, taxNames)
  taxNames[INED]<- sub(regex_ined_fin,"\\1",taxNames[INED])
  # sp numbered
  regex_sp_numbered<- "^([A-Z][[:alpha:]-]+) sp\\.? ?([0-9]{1,2}\\.?)$"
  caseSpNumbered<- grepl(regex_sp_numbered, taxNames)
  SP_N<-character(length(taxNames))
  SP_N[caseSpNumbered]<- sub(regex_sp_numbered, "\\2", taxNames[caseSpNumbered])
  taxNames[caseSpNumbered]<- sub(regex_sp_numbered, "\\1", taxNames[caseSpNumbered])
  # sp final
  regex_sp_final<- "^([A-Z][[:alpha:]-]+) sp\\.?$"
  SP_F<- grepl(regex_sp_final, taxNames)
  taxNames[SP_F]<- sub(regex_sp_final, "\\1", taxNames[SP_F])
  #spp final
  regex_spp_final<- "^([A-Z][[:alpha:]-]+) spp\\.?$"
  SPP_F<- grepl(regex_spp_final, taxNames)
  taxNames[SPP_F]<- sub(regex_spp_final, "\\1", taxNames[SPP_F])
  guessed_lev<- guess_level(taxNames = taxNames,regex_lev = lev_regex,exceptions = exceptions_guessLev)
  taxo_parts<-extract_taxParts(taxNames = taxNames, tax_lev = guessed_lev, regex_lev= lev_regex, extractPart = extract_part)
  names(taxo_parts)<- names(extract_part)
  return(list(taxs=data.frame(verbatim=sinParenth, taxName=taxNames,guessed_level=guessed_lev),
              taxo_extra=list(
                cf= data.frame(taxMatch= which(caseCf), verbatimCf= CF[caseCf]),
                aff= data.frame(taxMatch= which(caseAff), verbatimAff= AFF[caseAff]),
                Ined= which(INED),
                spNumbered= data.frame(taxMatch= which(caseSpNumbered), verbatimSp=SP_N[caseSpNumbered]),
                spF= which(SP_F),
                SPP_F= which(SPP_F),
                taxParts= taxo_parts,
                cataRef=data.frame(taxMatch=which(defTax!=""),catalog=defTax[defTax!=""])
                ),
              rareSpecies=rarePres
               )
         )
}
```


```{r}
getCompoPhytoXl<-function(sheet_unMerged, lev_regex, exceptions_guessLev, extractPart)
{
  lpc_info<-linePhytoCoverage(sheet_unMerged)
  rows_compo<-(lpc_info$line+1):nrow(sheet_unMerged)
  #sheet_unMerged[rows_compo,1]
  rows_onlyRownames<-which(apply(sheet_unMerged,1,function(x)!is.na(x[1])&all(is.na(x[2:length(x)]))))
  rows_oR_compo<-rows_onlyRownames[rows_onlyRownames>lpc_info$line]
  #rows_otrasEspecies<-rows_oR_compo[grepl(" *otras *especies *", sheet_unMerged[rows_oR_compo,1], ignore.case=T)]
  emptyRows<-which(apply(sheet_unMerged,1,function(x)all(is.na(x))))
  #if(length(rows_otrasEspecies)>1)
  #{warning("More than one line seems to delimit the \"other species\" zone.")
  #  rows_otrasEspecies<-line_otrasEspecies[1]
  #}
  #if(length(rows_otrasEspecies)==0)
  #{
    rowsTax<-rows_compo[(!rows_compo%in%rows_oR_compo)&!rows_compo%in%emptyRows]
  #}else{
  
  #rowsTax<-rows_compo[(!rows_compo%in%rows_oR_compo|rows_compo>rows_otrasEspecies)&!rows_compo%in%emptyRows]}
  taxDesc<-sheet_unMerged[rowsTax,1]
  taxo_treated<-treatTaxNameXlPhyto(taxDesc, lev_regex = lev_regex, exceptions_guessLev = exceptions_guessLev, extract_part = extractPart)
  
  as.matrix(sheet_unMerged[rowsTax,2:])
}
sheet_unMerged<-data_unMerged[[2]][[3]]
data_unMerged_all<-Reduce(c,data_unMerged)
Reduce(c,lapply(data_unMerged_all[sapply(data_unMerged_all,function(x)linePhytoCoverage(x)$lineFound)], getCompoPhytoXl))->taxNames
treatTaxo<- treatTaxNameXlPhyto(taxNames, lev_regex = taxo_treatNames_plant$regex_lev, exceptions_guessLev = taxo_treatNames_plant$exceptions,extract_part = taxo_treatNames_plant$extracPart)
lev_regex<-taxo_treatNames_plant$regex_lev
exceptions_guessLev<-taxo_treatNames_plant$exceptions
extractPart<-taxo_treatNames_plant$extracPart
```


